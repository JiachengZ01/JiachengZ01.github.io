---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi there, I am Jiacheng (James) Zhang. I am a research intern in the TikTok Data Trust & Safety team, mentored by [Dr Haoyu He](https://www.linkedin.com/in/haoyu-he-527526161/?originalSubdomain=au), and a Ph.D. candidate at [Trustworthy Machine Learning and Reasoning (TMLR)](https://github.com/tmlr-group) group in the Faculty of Engineering and Information Technology, the University of Melbourne under the supervision of [Dr. Feng Liu](https://fengliu90.github.io/) and [Prof. Ben Rubinstein](https://www.bipr.net/). Previously, I was an associate member of [Sea AI Lab (SAIL)](https://sail.sea.com/), mentored by [Dr. Tianyu Pang](https://p2333.github.io/) and [Dr. Chao Du](https://duchao0726.github.io/). I received my Honours degree with a University Medal (**Top 1** in my major) from the University of Sydney, where I was fortunate to learn from [A/Prof. Tongliang Liu](https://tongliang-liu.github.io/). Prior to that, I earned my Bachelor's degree from the University of Melbourne.

I am passionate about advancing the field of **trustworthy machine learning**, with a long-term vision of enabling **safe, reliable, and ethically aligned AI systems** that can be responsibly deployed in real-world environments. My current research interests lie in improving the **robustness** and **safety** of AI systems at multiple levels, including but not limited to: (1) safety alignment for multimodal AI agents; (2) safety alignment for large vision-language models; (3) adversarial robustness for vision models.

In an era where AI systems are increasingly embedded in high-stakes, real-world decision-making domains, I firmly believe that their foundations must be trustworthy and safe: not as an afterthought, but as a prerequisite for responsible and sustainable societal integration.

*Please feel free to email me for research, collaborations, or a casual chat.*

<!-- # üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìñ Educations
- *2023.08 - present*, the Unversity of Melbourne (Unimelb), Ph.D. in Engineering and IT, advised by [Dr. Feng Liu](https://fengliu90.github.io/) and [Prof. Ben Rubinstein](https://www.bipr.net/).
- *2022.07 - 2023.07*, the University of Sydney (USYD), B.Sc. in Data Science (Honours), advised by [A/Prof. Tongliang Liu](https://tongliang-liu.github.io/).
- *2019.03 - 2022.03*, the University of Melbourne (Unimelb), B.Sc. in Data Science.

# üìù Publications 
\* Co-first author, ‚úâÔ∏è Corresponding author.

<!-- DAD -->
<div class='paper-box'><div class='paper-box-image'><div>
<div class="badge">ICML 2025</div>
<img src='/_pages/figures/dad.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
One Stone, Two Birds: Enhancing Adversarial Defense Through the Lens of Distributional Discrepancy<br>
**Jiacheng Zhang**, Benjamin I.P. Rubinstein, Jingfeng Zhang, Feng Liu‚úâÔ∏è.<br>
In *ICML 2025*.
[[paper]](https://arxiv.org/pdf/2503.02169)
[[code]](https://github.com/tmlr-group/DAD)
[[poster]](/_pages/data/poster_DAD.pdf)
</div>
</div>

<!-- SSNI -->
<div class='paper-box'><div class='paper-box-image'><div>
<div class="badge">ICML 2025</div>
<img src='/_pages/figures/ssni.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
Sample-specific Noise Injection for Diffusion-based Adversarial Purification<br>
Yuhao Sun\*, **Jiacheng Zhang\***, Zesheng Ye\*, Chaowei Xiao, Feng Liu‚úâÔ∏è.<br>
In *ICML 2025*.
[[paper]](https://arxiv.org/pdf/2506.06027)
[[code]](https://github.com/tmlr-group/SSNI)
[[poster]](/_pages/data/poster_SSNI.pdf)
</div>
</div>

<!-- PART -->
<div class='paper-box'><div class='paper-box-image'><div>
<div class="badge">ICML 2024</div>
<img src='/_pages/figures/part.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
Improving Accuracy-robustness Trade-off via Pixel Reweighted Adversarial Training<br>
**Jiacheng Zhang**, Feng Liu‚úâÔ∏è, Dawei Zhou, Jingfeng Zhang, Tongliang Liu‚úâÔ∏è.<br>
In *ICML 2024*.
[[paper]](https://arxiv.org/pdf/2406.00685)
[[code]](https://github.com/tmlr-group/PART/)
[[poster]](/_pages/data/poster_PART.pdf)
</div>
</div>

# üéñ Honours and Awards
- *2025.07*, Optiver PhD Quant Lab Travel Scholarship.
- *2025.06*, ICML 2025 Travel Award.
- *2025.05*, ICML 2025 Top Reviewer (**Top 2%**).
- *2025.03*, Google Student Research Travel Scholarship.
- *2024.06*, ICML 2024 Travel Award.
- *2023.07*, Amazon Best UG Senior Project Award.
- *2023.07*, University Medal of USYD (**Top 1** in Major, Highest Honour for Undergraduates).
- *2023.06*, Melbourne Research Scholarship of Unimelb.
- *2021.02*, Mathematics and Statistics Vacation Research Scholarship of Unimelb.

# üíª Internships
- *2026.02 - Now*, research intern @TikTok - Data Trust & Safety, mentored by [Dr. Haoyu He](https://www.linkedin.com/in/haoyu-he-527526161/?originalSubdomain=au).
- *2025.08 - 2026.01*, research intern @[Sea AI Lab - Trustworthy AI](https://sail.sea.com/research/3), mentored by [Dr. Tianyu Pang](https://p2333.github.io/) and [Dr. Chao Du](https://duchao0726.github.io/).

# ‚úçÔ∏è Academic Services
- Conference Reviewer for ICML, NeurIPS, ICLR, CVPR, AISTATS, etc.
- Journal Reviewer for IEEE TPAMI, IEEE TIFS, TMLR, Machine Learning, NEUNET, etc.

# üí¨ Invited Talks
- *2025.12*, Invited Talk on *"How to Improve Model Robustness? A Distributional-Discrepancy Perspective"* @[Unimelb NLP Group Seminar](https://cis.unimelb.edu.au/research/artificial-intelligence/research/Natural-Language-Processing#news-and-events), Melbourne. 
[[slides]](/_pages/data/slides_2025_12_2.pdf)
- *2025.11*, Invited Talk on *"How to Improve Model Robustness? A Distributional-Discrepancy Perspective"* @[TMLR Seminar](https://trustworthy-ml.wixsite.com/seminar25nov), Melbourne. 
[[slides]](/_pages/data/slides_2025_11_21.pdf)
- *2025.08*, Invited Talk on *"Leveraging Distributional Discrepancies for Accuracy-robustness Trade-off"* @[AI TIME](https://www.aitime.cn/), Online. 
[[slides]](/_pages/data/slides_AI_TIME_ICML2025_2.pdf)
- *2025.06*, Invited Talk on *"Leveraging Distributional Discrepancies for Accuracy-robustness Trade-off"* @[AI TIME](https://www.aitime.cn/), Online. 
[[slides]](/_pages/data/slides_AI_TIME_ICML2025.pdf)
[[video]](https://www.bilibili.com/video/BV1i4KozXETv/?spm_id_from=333.337.search-card.all.click)
- *2025.01*, Invited Talk on *"Improving Accuracy-robustness Trade-off via Pixel Reweighted Adversarial Training"* @Unimelb, Melbourne. 
[[slides]](/_pages/data/slides_2025_1_23.pdf)
- *2024.11*, Invited Talk on *"Improving Accuracy-robustness Trade-off via Pixel Reweighted Adversarial Training"* @[AJCAI 2024](https://ajcai2024.org/index.html), Melbourne. 
[[slides]](/_pages/data/slides_AJCAI.pdf)

# üßë‚Äçüè´ Teaching Assistants
- Teaching Assistant for SWEN20003: Object Oriented Software Development (2024 S2 / 2025 S1 / 2025 S2).
- Teaching Assistant for COMP20008: Elements of Data Processing (2024 S1 / 2024 S2 / 2025 S1 / 2025 S2).